# -*- coding: utf-8 -*-
"""somrita.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RuETS73dN48oZAEuBbwx1KQajIHMHe41
"""

#import subprocess

#subprocess.run(["git", "clone", "https://github.com/SamSamhuns/yolov5_adversarial.git"])

import os

from PIL import Image
import numpy as np
import torch
import torch
import torchvision.transforms.functional as F
from PIL import Image
import matplotlib.pyplot as plt
import sys
sys.path.append("/home/bishakh/YOLO_project/yolov5_adversarial")
#os.chdir("/home/bishakh/YOLO_project/yolov5_adversarial")


from models.common import DetectMultiBackend

model = DetectMultiBackend("/home/bishakh/yolov5s.pt", device=torch.device("cuda" if torch.cuda.is_available() else "cpu"), dnn=False, data=None, fp16=False)


import cv2
from PIL import Image
import matplotlib.pyplot as plt
import torch
import numpy as np
from IPython.display import display
import torch
#!pip install ultralytics
from ultralytics import YOLO
import torchvision.transforms as transforms
from tqdm import tqdm
from tqdm import trange
img = cv2.imread('/home/bishakh/YOLO_project/droplets-hd-png-raindrops-1920.png',0)
#img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
print(img.shape)
img = cv2.resize(img,(928,512))
ret, thresh = cv2.threshold(img, 170, 255, cv2.THRESH_BINARY)
# Define a kernel for dilation (you can adjust the size as needed)
kernel = np.ones((2, 2), np.uint8)

# Perform dilation
thresh = cv2.erode(thresh, kernel, iterations=3)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
ath = cv2.cvtColor(thresh,cv2.COLOR_BGR2RGB)
plt.imshow(ath)
plt.show()

aimg = cv2.imread('/home/bishakh/YOLO_project/droplets-hd-png-raindrops-1920.png',0)
aimg = cv2.resize(aimg,(928,512))
aimg = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
print(img.shape)
plt.imshow(aimg)

import numpy as np
white = np.zeros((512,928))

contours, hierarchy = cv2.findContours(image=thresh, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)
num=0

# Choose a contour index (you may need to adjust this based on your specific use case)
for i in range(len(contours)):
  contour_index = i
  # Check if the contour is enclosed or open
  if hierarchy[0][contour_index][3] != -1 and cv2.contourArea(contours[contour_index]) > 200 : # :
      #print(f"Contour {contour_index} is enclosed.")
      num+=1

      # Plot the specific contour
      cv2.drawContours(white, contours, contour_index, (1), cv2.FILLED )

white = np.stack((white,) * 3, axis=-1)
awhite = (white * 255).astype(np.uint8)
awhite = np.stack((awhite,) * 3, axis=-1)
awhite = cv2.cvtColor(awhite,cv2.COLOR_BGR2RGB)
plt.imshow(white)

taimg=aimg.copy().astype(np.float32)
taimg=torch.tensor(taimg).permute(-1,0,1)[None,:,:,:]
taimg.shape
plt.imshow(taimg[0].permute(1,2,0).detach().numpy()/255)

twhite = white.copy().astype(np.float32)
twhite = torch.tensor(twhite).permute(-1,0,1)[None,:,:,:]
twhite.shape
plt.imshow(twhite[0].permute(1,2,0).detach().numpy())

def compute_total_variation_loss(delta, weight):  
        delta2 = torch.clamp(delta, -1, 1)
        tv_h = ((delta2[:,:,1:,:] - delta2[:,:,:-1,:]).pow(2)).sum()
        tv_w = ((delta2[:,:,:,1:] - delta2[:,:,:,:-1]).pow(2)).sum()   
        tv_h = torch.clamp(tv_h, -1000, 1000) 
        tv_w = torch.clamp(tv_w, -1000, 1000) 
        return weight * (tv_h + tv_w)

def give_mask(p=0.3):


  # Create a white image
  width, height = 928, 512
  white_image = torch.ones((3, height, width), dtype=torch.uint8) #* 255  # White image
  p=p
  # Draw a filled black rectangle on the white image
  rectangle_size = (int(p * width), int(p * height))
  x = torch.randint(0, width - int(p * width), (1,))
  y = torch.randint(0, height - int(p * height), (1,))

  white_image[:, y:y + rectangle_size[1], x:x + rectangle_size[0]] = 0
  white_image=white_image[None,:,:,:]
  #plt.imshow((purt*white_image)[0].permute(1,2,0).detach().numpy())
  return white_image
image_directory = '/home/bishakh/YOLO_project/bdd100k_images_10k/bdd100k/images/10k/train'
count=0
taimg = taimg.to('cuda')
twhite=twhite.to('cuda')
# Process each image in the directory
for filename in os.listdir(image_directory):
    count+=1
    image_path = os.path.join(image_directory, filename)
    ori= Image.open(image_path)
    ori = np.array(ori.resize((928,512)),dtype=np.float32)/255
    ori = torch.tensor(ori).permute(-1,0,1)[None,:,:,:].to('cuda')
    delta = 0.25*torch.ones_like(ori,dtype=torch.float32,requires_grad=True).to('cuda')
    delta = torch.nn.Parameter(delta)
    #plt.imshow(ori[0].permute(1,2,0).detach().numpy())
    #opt = torch.optim.Adam([delta], lr=10)

    opti = torch.optim.SGD([delta],lr=1)

    purt = delta*(taimg/255)#this aimg multiplication is giving the shading of the drops
    #plt.imshow(purt[0].permute(1,2,0).detach().numpy())
    purt = purt*give_mask(0.3).to('cuda')
    inimg = (1-twhite)*(ori) + twhite*((ori)*(taimg/255)*1.0 + 1.2*(1-(taimg/255))*purt)
    #plt.imshow(inimg[0].permute(1,2,0).detach().numpy())

    #plt.imshow(purt[0].permute(1,2,0).detach().numpy())


    taimg = taimg.to('cuda')
    inimg = inimg.to('cuda')
    ori = ori.to('cuda')
    twhite=twhite.to('cuda')
    delta = delta.to('cuda').detach().requires_grad_()
    with trange(1000) as t:
      for i in t:
        purt = delta*(taimg/255)#this aimg multiplication is giving the shading of the drops
        purt = purt*(give_mask(0.2).to('cuda'))
        inimg = (1-twhite)*(ori) + twhite*((ori)*(taimg/255)*1.0 + 0.6*(1-(taimg/255))*purt)
        #result=model(twhite*((ori)*(taimg/255)+ delta*(taimg/255))+(1-twhite)*(ori))[0]
        result=model(inimg)[0]
        
        class_confs = result[:, :, [14,17]]  #5:5 + 4 [batch, -1, n_classes] #change
        class_confs2 = result[:, :, [5,13]] 
        objectness_score = result[:, :, 4]
        loss = 2.2*class_confs.sum() + 10*(torch.norm(delta,2)) -class_confs2.sum() + compute_total_variation_loss(delta, 0.5)
        #print("loss:",loss)
        loss.backward()
        #print("delgrad:",delta.grad)
        t.set_postfix({"loss":loss.item(),"delgrad":delta.grad.sum()})
        delta.data = delta.data - 0.01*delta.grad.mean(dim=1)*delta.data
        delta.grad.zero_()
        #opti.step()
        #opti.zero_grad()
    if count % 1000 == 0:
        torch.save(delta, f'delta_tensor6_{count}.pth')
        torch.save(twhite, f'twhite6_{count}.pth')
        torch.save(taimg, f'taimg6_{count}.pth')
        torch.save(purt, f'purt6_{count}.pth')
